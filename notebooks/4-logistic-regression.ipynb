{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy.stats import norm\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "\n",
    "from modelling import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = {}\n",
    "data[2020] = pd.read_csv('../data/processed/scalar/wave_1.csv')\n",
    "data[2023] = pd.read_csv('../data/processed/scalar/wave_5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include the don't know answer in case of perceived_flood_frequency\n",
    "include_dont_know = False\n",
    "vif_threshold = 5.0\n",
    "significance_level = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Independent variables\n",
    "y_vars = [\n",
    "    'raise_ground_floor_level',\n",
    "    'strengthen_foundations',\n",
    "    'reinforce_walls_floor',\n",
    "    'raise_electricity_meter',\n",
    "    'install_anti_backflow_valves',\n",
    "    'install_pump_drainage',\n",
    "    'fix_water_barriers'\n",
    "]\n",
    "\n",
    "y_vars_ordered = {measure: i+1 for i, measure in enumerate(y_vars)}\n",
    "\n",
    "# Dependent variables\n",
    "X_vars = {\n",
    "        'threat_appraisal': [\n",
    "            'perceived_flood_frequency',\n",
    "            'flood_worry_level',\n",
    "            'experienced_flood'],\n",
    "        'coping_appraisal': {\n",
    "            'self_efficacy': [f'se{i+1}_{m}' for i, m in enumerate(y_vars_ordered)],\n",
    "            'response_efficacy': [f're{i+1}_{m}' for i, m in enumerate(y_vars_ordered)],\n",
    "            'perceived_costs': [f'pc{i+1}_{m}' for i, m in enumerate(y_vars_ordered)]},\n",
    "        'adaptive_behavior': [f'adapt{i+1}_{m}_agg' for i, m in enumerate(y_vars_ordered)],\n",
    "        'extra_vars': ['responsibility_perception']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_mappings = {\n",
    "    'perceived_flood_frequency': {\n",
    "        'My house is completely safe': 1,\n",
    "        'Less often than 1 in 500 years': 2,\n",
    "        'Once in 500 years': 3,\n",
    "        'Once in 200 years': 4,\n",
    "        'Once in 100 years': 5,\n",
    "        'Once in 50 years': 6,\n",
    "        'Once in 10 years': 7,\n",
    "        'Annually': 8,\n",
    "        'More frequent than once per year': 9,\n",
    "        \"Don't know\": np.nan,\n",
    "    },\n",
    "    'flood_worry_level': {\n",
    "        'Not at all worried': 1,\n",
    "        'A little worried': 2,\n",
    "        'Somewhat worried': 3,\n",
    "        'Quite worried': 4,\n",
    "        'Very worried': 5,\n",
    "    },\n",
    "    'rely_on_fam_friends': {\n",
    "        'Strongly agree': 1,\n",
    "        'Somewhat agree': 2,\n",
    "        'Neither agree nor disagree': 3,\n",
    "        'Somewhat disagree': 4,\n",
    "        'Strongly disagree': 5,\n",
    "    },\n",
    "    'rely_on_gov': {\n",
    "        'Strongly agree': 1,\n",
    "        'Somewhat agree': 2,\n",
    "        'Neither agree nor disagree': 3,\n",
    "        'Somewhat disagree': 4,\n",
    "        'Strongly disagree': 5,\n",
    "    },\n",
    "    'responsibility_perception': {\n",
    "        'Completely government': 1,\n",
    "        'Mostly government': 2,\n",
    "        'Equal responsibility': 3,\n",
    "        'Mostly individual': 4,\n",
    "        'Completely individual': 5,\n",
    "    }\n",
    "}\n",
    "\n",
    "if include_dont_know:\n",
    "    nominal_cols = ['experienced_flood', 'perceived_flood_frequency_dont_know']\n",
    "else:\n",
    "    nominal_cols = ['experienced_flood']\n",
    "\n",
    "y_mappings = {'Will not implement': 0, 'Will implement': 1, 'Already implemented': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile variables and mappings into config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'variables': X_vars,\n",
    "    'structural_measures': y_vars_ordered,\n",
    "    'ordinal_mappings': ordinal_mappings,\n",
    "    'include_dont_know': include_dont_know,\n",
    "    'nominal_cols': nominal_cols,\n",
    "    'y_mappings': y_mappings,\n",
    "    'vif_threshold': vif_threshold,\n",
    "    'significance_level': significance_level\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_2020_results, wave_2020_summary = run_wave_analysis(data[2020], 2020, config)\n",
    "wave_2023_results, wave_2023_summary = run_wave_analysis(data[2023], 2023, config)\n",
    "\n",
    "results_by_wave = {\n",
    "    2020: wave_2020_results,\n",
    "    2023: wave_2023_results,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_tests(results_by_wave):\n",
    "    rows = []\n",
    "    for wave, res_list in results_by_wave.items():\n",
    "        for res in res_list:\n",
    "            m = res['structural_measure']\n",
    "            stats = res['full_stats']\n",
    "            for _, r in stats.iterrows():\n",
    "                rows.append({\n",
    "                    'wave': wave,\n",
    "                    'measure': m,\n",
    "                    'variable': r['variable'],\n",
    "                    'coef': r['coef'],\n",
    "                    'se': r['se'],\n",
    "                    'p': r['p'],\n",
    "                    'OR': r['OR'],\n",
    "                    'OR_lo': r['OR_lo'],\n",
    "                    'OR_hi': r['OR_hi']\n",
    "                })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "tests_df = collect_tests(results_by_wave)\n",
    "tests_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_wave_fdr(df):\n",
    "    out = []\n",
    "    for wave, g in df.groupby('wave', as_index=False):\n",
    "        rej, q, _, _ = multipletests(\n",
    "            g['p'].values, alpha=0.05, method='fdr_bh')\n",
    "        tmp = g.copy()\n",
    "        tmp['q_wave'] = q\n",
    "        tmp['sig_wave'] = rej\n",
    "        out.append(tmp)\n",
    "    return pd.concat(out, ignore_index=True)\n",
    "\n",
    "tests_df = add_wave_fdr(tests_df)\n",
    "tests_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lookup = tests_df.set_index(['wave', 'measure', 'variable'])[\n",
    "    'q_wave'].to_dict()\n",
    "\n",
    "alpha = 0.05\n",
    "for wave, res_list in results_by_wave.items():\n",
    "    for res in res_list:\n",
    "        m = res['structural_measure']\n",
    "        # columns: variable, coef, se, p, ci_lo, ci_hi, OR, OR_lo, OR_hi\n",
    "        fs = res['full_stats'].copy()\n",
    "        # add q and display name\n",
    "        fs['q_wave'] = fs['variable'].map(\n",
    "            lambda v: q_lookup.get((wave, m, v), np.nan))\n",
    "        fs['display_var'] = fs['variable'].apply(display_name)\n",
    "\n",
    "        # add flag: significant by p but NOT by q\n",
    "        fs['sig_p_only'] = (\n",
    "            (fs['p'] < alpha) & (fs['q_wave'] >= alpha) & (fs['variable'] != 'const')\n",
    "        )\n",
    "\n",
    "        res['full_stats'] = fs\n",
    "\n",
    "        # significant rows by FDR within wave\n",
    "        sig_rows = fs[(fs['variable'] != 'const') &\n",
    "                      (fs['q_wave'] < alpha)].copy()\n",
    "\n",
    "        # keep one row per display_var (there should be at most one anyway)\n",
    "        sig_rows = sig_rows.drop_duplicates(subset=['display_var'])\n",
    "\n",
    "        # store display names only\n",
    "        res['significant_vars'] = sig_rows['display_var'].tolist()\n",
    "\n",
    "        # build dicts keyed by display_var, values from the row\n",
    "        res['significant_vars_odds_ratio'] = {\n",
    "            r['display_var']: r['OR'] for _, r in sig_rows.iterrows()}\n",
    "        res['significant_vars_pvalues'] = {\n",
    "            r['display_var']: r['p'] for _, r in sig_rows.iterrows()}\n",
    "        res['significant_vars_confidence_intervals'] = {r['display_var']: (\n",
    "            r['OR_lo'], r['OR_hi']) for _, r in sig_rows.iterrows()}\n",
    "        res['significant_vars_qvalues'] = {\n",
    "            r['display_var']: r['q_wave'] for _, r in sig_rows.iterrows()}\n",
    "\n",
    "        # store variables that are significant by p but not by q\n",
    "        sig_p_only_rows = fs[fs['sig_p_only']]\n",
    "        res['sig_by_p_not_q'] = sig_p_only_rows['display_var'].tolist()\n",
    "\n",
    "        # Print variables that are significant by p but not by q\n",
    "        if len(res['sig_by_p_not_q']) > 0:\n",
    "            print(f\"Wave: {wave}, Measure: {m}, Variables significant by p only (not q): {res['sig_by_p_not_q']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_by_wave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_or_matrix = create_odds_ratio_matrix(\n",
    "    results_by_wave, protective_threshold=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_index = {'raise_electricity_meter': 'Raise electricity meter',\n",
    "                   'install_anti_backflow_valves': 'Install anti-backflow valves',\n",
    "                   'install_pump_drainage': 'Install pump/drainage',\n",
    "                   'fix_water_barriers': 'Fix water barriers',\n",
    "                   'strengthen_foundations': 'Strengthen foundations',\n",
    "                   'reinforce_walls_floor': 'Reinforce walls/floor',\n",
    "                   'raise_ground_floor_level': 'Raise ground floor level'}\n",
    "\n",
    "column_names = {'self_efficacy': 'Self-efficacy',\n",
    "                'responsibility_perception': 'Responsibility perception',\n",
    "                'flood_worry_level': 'Flood worry level',\n",
    "                'experienced_flood_Yes': 'Experienced flood',\n",
    "                'perceived_flood_frequency': 'Perceived flood frequency'}\n",
    "\n",
    "wave_2020 = formatted_or_matrix.loc[2020]\n",
    "wave_2023 = formatted_or_matrix.loc[2023]\n",
    "\n",
    "wave_2020 = wave_2020.reindex(sorted_index.keys())\n",
    "wave_2020.index = [sorted_index[i] for i in wave_2020.index]\n",
    "wave_2020.columns = [column_names[i] for i in wave_2020.columns]\n",
    "wave_2020.drop(index=['Raise ground floor level'], inplace=True)\n",
    "\n",
    "wave_2023 = wave_2023.reindex(sorted_index.keys())\n",
    "wave_2023.index = [sorted_index[i] for i in wave_2023.index]\n",
    "wave_2023.columns = [column_names[i] for i in wave_2023.columns]\n",
    "wave_2023.drop(index=['Raise ground floor level'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_2023"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "crl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
